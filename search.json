[{"title":"变量","url":"/2020/11/29/变量/","content":"\n\n变量，对于我们程序员来说，太容易理解不过了，简单来说就是引起各种情况发生的因子，因为有这个因子存在，所以事情都不存在确定性，因为我们都害怕不确定性，所以我们经常从历史经验中来寻找应对这些不确定的情况的方法。\n\n在作者眼里，变量是影响历史进程的关键因子，变量又分为慢变量与快变量。\n\n> 我来举例说明什么是快变量，什么是慢变量。天气预报能告诉你台风即将登陆，海上会有大浪，但是，只看天气预报，你永远无法理解为什么海上会有波浪。导致海上有波浪的真正原因是有月亮和太阳。月亮和太阳的引潮力引发潮汐现象。每逢农历初一和十五，也就是朔日和望日，月亮和太阳的引潮力方向相同，会产生大潮，也称朔望潮；每逢农历初八和廿二，也就是上弦和下弦，月亮和太阳的引潮力互相削弱，会产生小潮，也称方照潮。天气是快变量，月亮和太阳是慢变量。\n\n我理解慢变量是导致某种变化的本质，比如说工业革命、电气革命，把时间跨度拉长来看，现在的信息革命都是在享受上一次工业革命的红利。快变量则是展示出来的表面现象，如月亮的圆缺，天气的变化。有一句我们常说的话，快即是慢，慢即是快。我觉得跟作者的思路很像，也符合我们做事的原则，解决问题应该找本质，可能刚开始理解、寻找问题的本质很慢，但是一旦熟悉之后，就会有成倍的收益，也便于日后解决类似的问题，这为以后解决快问题打下基础，提供解决问题的速度。\n\n作者进行了归纳：影响历史进程的慢变量有三个工业化、城市化和技术创新。\n\n除了变量，还需要关注趋势，大趋势与小趋势。\n\n> 我们关注小趋势，有两个主要的原因：第一，随着社会的发展，社会分化日益显著，大趋势不足以准确描述社会的多向度发展；第二，从社会演进的角度来看，很少出现泾渭分明的新旧交替，新的观念、新的现象往往是由原有的一些小趋势发源的，这些小趋势原本并不占据主流地位，但随着社会的变化，却能引起社会风尚的深刻变革。\n\n何为大趋势，何为小趋势？\n\n我认为大趋势就是信息化，小趋势就是 PC 、 手机移动、物联网 并驾齐驱，并不会因为某个趋势的出现而把另外一个淘汰，以前人们都说移动互联网是未来，手机APP开发，在2011年左右是相当的火，现在来看，这不仅不会把PC端淘汰，而且PC端视乎并没有减弱的趋势。我觉得这就是小趋势，遍地开花。\n\n> **发展初期看大趋势，发展后期看小趋势**。在发展的初期，更重要的是大趋势。我们所有人都被大趋势裹挟着前进，那个时候，想要理解自己所处的时代并不难，就像行军的时候，你只需要跟着前面的伙伴，甚至拉着马尾巴朝前走就行。在社会和经济发展到一定的阶段之后，反而会出现分化。国家和国家变得更不一样，城市和城市变得更不一样，企业和企业变得更不一样，个人和个人变得更不一样。也就是说，人们首先得变得更相似、更平等、更富裕，然后才能变得更加差异化。**在未来时代，小众才是主流。**\n\n作者通过实地走访，看见了 5个 变量：\n\n##### 大国博弈\n\n当新兴国家的崛起，威胁着霸权国家的地位，大国之间的博弈会越发频繁，是一群想上车的人与想下车的人的矛盾。\n\n##### 技术赋能\n\n科技在发展，技术在创新，如何把科技应用与实际生产，作者举了个无人机的例子：找准场景、匹配需求、技术改造再改造。\n\n##### 新旧融合\n\n由于技术创新，新技术与老技术之间也需要融合发展，新技术需要向老技术学习，因为一起都是为了解决问题，老技术有一些新技术没有的优点，只有他们相互融合，脚步一致才会碰撞出爱的火花。\n\n##### 自下而上\n\n过去城市化都是自上而下，现在需要自下而上，按我的理解是 基础决定上层结构，上层规划的再好，下层不稳也不会长久。\n\n高手在民间。\n\n##### 重建社群\n\n现在我们不仅需要物资上富裕，还需要精神上的富裕，在能赚钱的地方找不到自己的精神家园。第一人生是满足物资需要，第二人生满足精神需求。可惜，现在大多人还在为物资需求进行奋斗，等大家物资差不多都充裕了，就需要寻求自己的精神家园，这个过程可能就是重建社群的过程。\n\n希望以后真如作者描述的那样：\n\n> 一个人的力量是渺小的，无法阻挡世间的洪流，但可以让身边的小环境变得更有尊严、更有趣味。阿那亚和聚龙小镇并不是孤岛，而是群岛。很快这些群岛上的灯光就能连成一片，让相邻的岛上的人们能够彼此相望，感到心安和温暖，同时也能慰藉那些依然在海上漂泊，在迷茫、冷漠和不解中挣扎的孤舟。\n\n\n变量，会一直影响我们的生活。\n","tags":["变量"]},{"title":"Redis基础4_数据持久化之RDB","url":"/2020/09/24/Redis基础-数据持久化之RDB/","content":"\n> 上篇说了Redis持久化之AOF，他有利也有弊，利是每次执行时追加的AOF数据不多，只要不配置成Always效率影响不会很大，弊是当我们需要恢复数据时，因为是每个命令都写入了AOP所以恢复时间比较长，所以出现了另外一种持久化方法 RDB：把Redis的数据快照 保存下来，因为保存的全是数据，所以恢复时直接写入内存即可，恢复速度比较快。\n\n<!--more -->\n\n使用RDB持久化，需要搞清楚两个问题：\n\n1. 是否阻塞线程？服务器是否能够继续处理请求？\n2. 每次持久化是全量数据吗？\n\n\n\n#### 是否阻塞线程？服务器是否能够继续处理请求？？\n\nRDB持久化有两个命令： `save` 和 `bgsave` save是在主线程中执行，会阻塞线程；`bgsave`不会阻塞线程，由于是fork出子线程进行RDB持久化，那么服务器就可以继续处理请求，读请求还好说，不改变内存数据，那么写请求时，redis如何处理？而且redis使用RDB持久化，是持久化`全量快照数据`，当数据量很大时，效率必定不会很高。\n\n但是，这时RedisServer 是可以处理写请求的，他是怎么处理的？\n\n注意上面`bgsave`命令是fork出子线程，这时子线程是可以访问父进程的内存数据的，Redis就利用操作系统的[写时复制](https://www.cnblogs.com/biyeymyhjob/archive/2012/07/20/2601655.html)技术，把父进程修改的数据，复制一份给子进程，这样子进程还是保存的是最新的数据，父进行还是可以处理写请求。\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/image-20200924155944631.png\" alt=\"image-20200924155944631\" style=\"zoom:50%;\" />\n\n#### 每次持久化是全量数据吗？\n\n如果内存数据很多很大，每次持久化全量数据势必会影响效率，所以Redis4.0以后有了“增量快照功能”，其实是全量快照+AOF日志结合起来使用，第一次全量快照后，每隔一段时间再次做全量快照；两次全量快照的时间间隔间，使用AOF日志记录变化的数据。\n\n如图：\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/image-20200924161409328.png\" alt=\"image-20200924161409328\" style=\"zoom:50%;\" />\n\n\n\n假如，在两次全量快照的时间之中，发生了宕机，可以使用RDB来快速恢复数据，同时利用AOF日志来做增量恢复。\n\n\n\n\n\n\n","tags":["redis"]},{"title":"Redis基础3_数据持久化之AOF","url":"/2020/09/11/Redis基础3-数据持久化之AOF/","content":"\n>  Redis有两种数据持久化的方式，他们都有各自的特点，写下AOF持久化的总结。\n\n<!--more -->\n\n### AOF持久化\n\nAOF是Append Only File 的简称，AOF是利用日志来记录Redis的操作命令，然后在使用他恢复Redis数据。\n\n提到日志，有两个很经典的应用场景，MySQL的两阶段提交，就是利用日志来实现的，还有消息队列如rocketMQ也是利用写日志来记录数据，但是有个明显的区别，他们一般是先写日志，后刷盘这样能够避免数据丢失，**但是Redis不一样，Redis是先执行命令后写日志**。\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/image-20200911160600899.png\" alt=\"image-20200911160600899\" style=\"zoom:50%;\" />\n\n如果这时候，Redis写了内存，还没有写日志，挂掉了怎么办？数据还能恢复吗？\n\n答案是不能，所以会有数据丢失的风险。\n\n那为什么Redis会选择这种方式？\n\n1. 由于AOF日志记录的是Redis的命令，后写日志避免了AOF日志记录错误的命令（为什么不检查正确后在写日志？）\n2. 由于Redis处理数据时是单线程，如果先写日志，当磁盘有性能问题时，会有阻塞当前请求的线程的风险，但是这种风险避免不了。为啥？因为后写日志，如果你磁盘有问题，会影响下次请求。（写AOF日志是在主线程中完成）\n\n**所以，为了避免磁盘引发的风险，Redis提供了三种AOF写回策略。**\n\nappendfsync 配置：\n\nAlways：每次执行完命令，立刻写AOF日志到磁盘\n\nEverysec： 每秒写回，命令执行完，先把AOF日志写到内存缓冲区，每隔一秒把内存缓存区的AOF日志写到磁盘\n\nNo： 操作系统控制写回，命令执行完，先把AOF日志写到内存缓冲区，由操作系统决定何时写回磁盘。\n\n> **操作系统何时写回磁盘？**\n>\n> 在现代操作系统中， 当用户调用 `write` 函数， 将一些数据写入到文件的时候， 操作系统通常会将写入数据暂时保存在一个内存缓冲区里面， 等到缓冲区的空间被填满、或者超过了指定的时限之后， 才真正地将缓冲区中的数据写入到磁盘里面。也就是说如果你不强制调用系统的同步函数，这个权限就交给操作系统了。\n>\n> 这种做法虽然提高了效率， 但也为写入数据带来了安全问题， 因为如果计算机发生停机， 那么保存在内存缓冲区里面的写入数据将会丢失。\n>\n> 为此， 系统提供了 `fsync` 和 `fdatasync` 两个同步函数， 它们可以强制让操作系统立即将缓冲区中的数据写入到硬盘里面， 从而确保写入数据的安全性。 也就是说，Always和Everysec都调用 同步函数。\n\n比较一下三种方式：\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/image-20200911162720796.png\" alt=\"image-20200911162720796\" style=\"zoom:50%;\" />\n\n这时候，如果AOF开启，这明显有个问题，随着Redis系统的运行，AOF文件会越来越大，当发生系统宕机时，AOF恢复是很头痛的问题，所以Redis引入了**AOF重写机制**。\n\nAOF重写机制，实际上就是把多个命令变成了一个命令，然后写入AOF文件，比如有6个命令对 test 这个key做了修改，AOF重写机制会选择最新的 test key的状态 写入AOF文件。\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/image-20200911163232926.png\" alt=\"image-20200911163232926\" style=\"zoom:50%;\" />\n\n**那Redis何时进行AOF重写？**\n\n1. 手动触发，使用`BGREWRITEAOF`\n\n2. 服务器自动进行重写\n\n   > 服务器在AOF功能开启的情况下，会维持以下三个变量：\n   >\n   > 1. 记录当前AOF文件大小的变量`aof_current_size`\n   > 2. 记录最后一次AOF重写之后，AOF文件大小的变量`aof_rewrite_base_size`\n   > 3. 增长百分比变量`aof_rewrite_perc`。\n   >\n   > 每次当`serverCron`（服务器周期性操作函数）函数执行时，它会检查以下条件是否全部满足，如果全部满足的话，就触发自动的AOF重写操作：\n   >\n   > 1. 没有BGSAVE命令（RDB持久化）/AOF持久化在执行\n   > 2. 没有BGREWRITEAOF在进行\n   > 3. 当前AOF文件大小要大于`server.aof_rewrite_min_size`（默认为1MB），或者在`redis.conf`配置了`auto-aof-rewrite-min-size`大小\n   > 4. 当前AOF文件大小和最后一次重写后的大小之间的比率等于或者大于指定的增长百分比（在配置文件设置了`auto-aof-rewrite-percentage`参数，不设置默认为100%）\n   >\n   > 如果前面三个条件都满足，并且当前AOF文件大小比最后一次AOF重写时的大小要大于指定的百分比，那么触发自动AOF重写\n\n**AOF重写是否会阻塞主线程处理请求的命令？**\n\n答案是不会阻塞主线程，由主线程fork出子线程完成 AOF的重写。\n\n每次执行AOF重写时，主线程会fork出 `bgrewriteaof` 线程（注意，由于是fork当内存数据较多时，虽然不会拷贝父进程的内存数据，但是会拷贝父进程的空间内存页表，我们可以在 Info stats 统计中查询 latestforkusec 指标获取最近一次 fork 操作耗时，单位微秒），此时  `bgrewriteaof` 线程会共享主线程的内存数据，内存数据时最新的，那么现在子线程就可以生产一个 AOF重写日志（**此时访问父进程的数据，是把全部内存数据都生产AOF重写日志吗？**）\n\n此时，有个问题，主线程还可以继续处理请求，可能主线程会更新内存中的数据，所以还需要依赖另外一个日志来处理 主线程更新后的数据：这时候还会生产主线程操作的AOF重写日志，待主线程完成操作后，再将子线程的AOF重写日志与主线程的重写日志合并。\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/image-20200911165649730.png\" alt=\"image-20200911165649730\" style=\"zoom:50%;\" />\n\n\n\n\n"},{"title":"一次团队内的产品技术分享","url":"/2020/09/10/一次团队内的产品技术分享/","content":"\n> 记录：一次分享PPT制作\n\n<!--more -->\n\n#### 利用脑图整理大纲\n\n这几天需要给团队做一次产品技术分享，主要是分享一下我们团队做的一个产品《XXX营销系统》，这个产品是一个很常规的产品，可以满足大多数营销场景。\n\n为了做这个PPT 我很是苦恼，不知道从何下手也不知道如何进行制定演讲内容，内容与内容之间如何进行衔接，最后我决定先列出要讲的大纲，然后分别制定好每个PPT需要演讲的内容，然后才是PPT的制作，对于没有艺术功底的我来说也是一项繁重的任务。\n\n首先，列出需要演讲的内容，我使用脑图来梳理我需要演讲的内容：\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/image-20200910160821116-9727644.png\" alt=\"image-20200910160821116\" style=\"zoom:50%;\" />\n\n使用脑图很方便的列出我需要讲的大纲，有了大纲我才可以继续梳理，每个大纲需要将什么内容；同时我也会思考每个点如何进行承上启下。有了大概，我继续细化每个点需要讲的内容，由于涉及公司内容，这里就不贴了。\n\n#### 选择合适图形与图表\n\n大纲差不多整理完了，那就可以进行下一步了，选择一个具有科技股的模板，一般我优先选择蓝色的。\n\n推荐网址：http://www.ypppt.com/ \n\n里面有个模块不错：http://www.ypppt.com/tubiao/  图标模块，当我不知道如何展示一个内容的时候，我会去这里找灵感。\n\n加上自身的逻辑，很容易找到图表的展示方式。\n\n在制作的过程中，有些我们需要一些图标，最好选择矢量图，推荐网址：https://www.iconfont.cn/home/index?spm=a313x.7781069.1998910419.2 阿里巴巴的图标搜索\n\n#### 克服语言障碍进行试讲\n\nPPT 制作完成之后，我自己给领导进行了一次试讲，领导会点评，有个好方法是全程录音，因为事后可能需要总结和修改，你通过录音能够复盘，哪里讲的不好，哪里需要进行着重渲染，上下文怎么衔接，是否有遗漏的地方，都可以通过复盘来找出来。\n\n\n\n"},{"title":"Redis基础2_为什么选择单线程","url":"/2020/08/21/Redis基础2-为什么选择单线程/","content":"\n> 最近重温redis基础知识的学习随笔，随便写写\n\n<!--more -->\n\n\n我们都知道Redis是单线程模型的内存KV数据库（网络IO与键值对读写单线程），可是为啥Redis选择了单线程，现在大多数服务器都是64G+12核心左右，为什么Redis选择了单线程？\n\n#### 多线程带来什么问题？\n\n平常做Java开发,都涉及到多线程,直观的感觉,多线程比单线程快,其实当线程数多到一定程度,执行效率可能还没有单线程快。\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/20200820161046.png\" style=\"zoom:50%;\" />\n\n多线程也分应用场景\n\n计算型操作，多线程用起来相对比较高效\n\nIO型操作，多线程用起来提升不了多大性能\n\n##### 线程模型设计比单线程模型复杂\n\n多线程模型涉及到共享数据，锁的粒度大小，如果设置的不合理都会导致效率不高；\n\n##### 多线程线程切换带来的成本\n\n多线程切换时有一定的性能损耗，即使不一般不大，但是也会有一定影响\n\n##### 不易调试与维护\n\n多线程模型，引入了并发，多线程代码降低了代码的可读性与可维护性\n\n#### Redis单线程为什么快？\n\n##### Redis是内存数据库\n\n大部分Redis操作都是在内存上完成\n\n##### Redis优秀的存储数据结构\n\nRedis的内部的数据结构时间复杂度大多是 O(logN) O(1)，范围扫描等时间复杂度是O(N)\n\n##### Redis使用了多路复用的IO模型\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/image-20200820165211392.png\" alt=\"image-20200820165211392\" style=\"zoom:50%;\" />\n\n多路IO复用极大的提高了Redis的IO效率，可以看到图中，连接绑定上之后，会有多种事件，所有的事件都存放到了Redis一个队列中，事件出队，Redis使用一个线程来处理具体的事件。\n\n\n\n当然，任何架构都不是完美的，可以从上图的IO模型看到，这个队列是Redis的性能瓶颈。\n\n1. 队列中的任何事件，如果处理事件（请求）耗时，则整个Redis服务会受到影响\n2. Big Key 会损耗内存\n3. 复杂度高的命令，对redis影响比较大 O(N),如：keys *  SORT等\n\n\n"},{"title":"Redis基础学习1","url":"/2020/08/17/Redis基础学习1/","content":"\n> 最近重温redis基础知识的学习随笔，随便写写\n\n<!--more -->\n\nredis本质上是一个hash表，复杂度为O(1);\n\nKey 一般是个String类型，Value可以包含多种类型:String、List、Hash、SortedSet、Set；github上有人对redis3.0做了注释，有空可以看看源码：[redis3.0源码注释](https://github.com/frankan0/redis-3.0-annotated/blob/unstable/src/dict.h)\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/20200817154827-20200817164744005.png\" style=\"zoom:50%;\" />\n\n具体定义的代码：\n\n```c\n//字典定义\ntypedef struct  dict{\n    dictType *type;  //type和privdata是针对不同类型的键值对，为创建多态字典而设置的\n    void *privdata;\n    dictht ht[2];  //两个hashtable，用于存储和rehash\n    long rehashidx;  //如果没有进行rehash，则值为-1，否则，rehash表示rehash进行到的索引位置\n    unsigning long iterators;\n}dict;\n\n//哈希表定义\ntypedef struct dictht {\n    dictEntry **table;  //指针，指向一个哈希桶bucket\n    unsigning long size;  //哈希表的大小\n    unsigning long sizemask;  //总是size-1，这个值和哈希值一起决定元素应该定位到桶中的什么位置\n    unsigning long used;  //已使用的桶数量\n}dictht;\n\n//具体键值对定义\ntypedef struct dictEntry{\n    void *key;   //键值\n    union{\n        void *val;  //value值\n        unint64_tu64;\n        int64_ts64;\n    }v;\n    struct dictEntry *next;  //指向下一个键值对的指针，用于解决哈希冲突问题\n}dictEntry;\n```\n\n在这个大的hash表中，实际上Value都存储的是指针；\n\n本质上是大的Hash表，就有个通用的问题：（类似Java的hashMap）\n\n1. 如何解决hash冲突\n2. 何时进行扩容\n3. 如何扩容Hash表\n\n\n\n#### 如果解决hash冲突？\n\n跟Java的hashMap一样，redis采用链式hash解决hash冲突，如果存在相同的KEY，则在hash桶中，增加一个节点，如图：\n\n<img src=\"https://frankblogimgs.oss-cn-beijing.aliyuncs.com/20200817155047-20200817164810911.png\" style=\"zoom:50%;\" />\n\n当数据越来越大，随之而来的是冲突越来越多，这个链表则会越来越长，此时，redis会进行hash桶的扩容，俗称“rehash\";\n\nJava里面的HashMap也有这个操作，不过，Java8在内部做了一个优化，当冲突链表超过8个时，会转化成红黑树，有个”树化“的过程。\n\n#### 何时进行扩容？\n\nJava里面有个负载因子，默认为0.75，当大于这个负载因子时，hashMap就进行扩容。\n\n负载因子 = 哈希表保存的KEY的数量 / 哈希表的大小\n\nredis中，这个跟hashMap类似，超过阈值时进行扩容\n\n#### 如何扩容hash表？\n\nJava中的HashMap扩容是直接进行复制。而redis中，则是\"渐进式扩容\"可以看到上面 字典的定义：\n\n```c\n//字典定义\ntypedef struct  dict{\n    dictType *type;  //type和privdata是针对不同类型的键值对，为创建多态字典而设置的\n    void *privdata;\n    dictht ht[2];  //两个hashtable，用于存储和rehash\n    long rehashidx;  //如果没有进行rehash，则值为-1，否则，rehash表示rehash进行到的索引位置\n    unsigning long iterators;\n}dict;\n```\n\n定义了两个hashtable，一个hashtable正常处理业务逻辑，另外一个就是在rehash时，需要使用的hashtable。\n\n- 处理请求时进行rehash的搬运操作\n\n  每次请求时，如果正在rehash操作，则本次请求中，将本次查询的hash槽进行搬运。\n\n- redis定时进行rehash的搬运操作\n\n  定时的进行rehash操作，这个只有在服务器空闲时进行，且每次只操作100个槽，每次不超过1ms\n\n\n\n这样redis就完成了，渐进式的rehash操作。\n\nredis的字典表跟Java的hashMap结构还是有很多相似之处，有时候可以放在一个维度上进行对比，加深理解，建立网状的知识结构，后面你就会发现很多其实是相同的，比如RPC，消息队列，数据库有很多地方都是相同的，怎么进行通信，如果存储数据，怎么实现两阶段提交等等\n\n","tags":["redis hash"]},{"title":"socks5协议与客户端简单实现","url":"/2020/05/29/socks5协议与客户端简单实现/","content":"\n\n> 在国内，如果想要访问google等被封锁的网站，我们想要翻墙，一直以来都是自己搭建翻墙软件，有一些一键部署脚本，今天受一个朋友委托想要做手机端的代理软件，所以就研究了一下这个协议；为以后开发android的代理软件（并非FQ软件）打下基础。\n\n<!--more -->\n\n\n首先，socks5协议并非网络编程中的sockets，socks是一种协议最新版本应该是socks5;而sockets是一种网络编程方法,是一种工具，就像打电话，socks5可以理解为某种交流语言，而sockets是电话。\n\nsocks协议是会话层协议，这就表明，他可以无视会话层之上的协议，如http等应用层协议,也就是说可以代理HTTP等上层协议；由于是会话层协议，所以他依赖TCP/IP协议。\n\n著名的shadowsocks就是基于此协议，但是shadowsocks提供了丰富的加密功能，而`socks5是不具备加密功能的`。\n\nsocks协议有很多版本，如socks4,socks4a,socks5 最新版本是socks5,提供了UDP代理，认证，IPV6功能。\n\n这次主要研究socks5；\n\n需要注意的是，当客户端与服务器端`建立TCP连接之后`才会根据`socks5协议进行握手`。\n\nsocks5协议内容(`以字节为单位`):\n\n##### 客户端请求握手\n\n建立连接之后，客户端发出握手请求：\n\n| VER  | NMETHODS | METHODS |\n| ---- | -------- | ------- |\n| 1    | 1        | 1-255   |\n\n- VER是SOCKS版本，这里应该是0x05\n\n- NMETHODS是METHODS部分的长度\n- METHODS是客户端支持的认证方式列表，每个方法占1字节。当前的定义是：\n  - 0x00 不需要认证 (常用)\n  - 0x01 GSSAPI\n  - 0x02 用户名、密码认证 (常用)\n  - 0x03 - 0x7F由IANA分配（保留）\n  - 0x80 - 0xFE为私人方法保留\n  - 0xFF 无可接受的方法\n\n##### 服务端回应握手信息\n\n| VER  | METHOD |\n| ---- | ------ |\n| 1    | 1      |\n\n- VER是SOCKS版本，这里应该是0x05；\n- METHOD是服务端选中的方法。如果返回0xFF表示没有一个认证方法被选中，客户端需要关闭连接。\n\n如果服务端允许直接访问或者用户名密码认证访问,Method 应该是0x00或者是0x02\n\n##### 客户端发送认证请求\n\n| 鉴定协议版本 | 用户名长度 | 用户名 | 密码长度 | 密码 |\n| ------------ | ---------- | ------ | -------- | ---- |\n| 1            | 1          | 动态   | 1        | 动态 |\n\n协议版本目前固定为 0x01\n\n这里必须要注意一下，用户名长度与密码长度；\n\n一般用户名和密码都是字符串，这里需要把 String->16进制字符串->byte数组 ;这个长度就是数组的长度。\n\n用户名与密码都传入这个byte数组就行。\n\n为什么是16进制？16进制比较好认。\n\n##### 服务器认证应答\n\n| 鉴定协议版本 | 鉴定状态 |\n| ------------ | -------- |\n| 1            | 1        |\n\n协议版本目前固定为 0x01\n\n其中鉴定状态 0x00 表示成功，0x01 表示失败。\n\n认证成功之后，客户端就可以发送请求信息，比如 客户端需要访问baidu.com就需要发送请求信心，让服务端去请求baidu.com\n\n##### 客户端请求命令\n\n| VER  | CMD  | RSV  | ATYP | DST.ADDR | DST.PORT |\n| ---- | ---- | ---- | ---- | -------- | -------- |\n| 1    | 1    | 0x00 | 1    | 动态     | 2        |\n\n- VER是SOCKS版本，这里应该是0x05；\n- CMD是SOCK的命令码\n  - 0x01表示CONNECT请求\n  - 0x02表示BIND请求\n  - 0x03表示UDP转发\n\n- RSV 0x00，保留\n- ATYP DST.ADDR类型\n  - 0x01 IPv4地址，DST.ADDR部分4字节长度\n  - 0x03 域名，DST.ADDR部分第一个字节为域名长度，DST.ADDR剩余的内容为域名，没有\\0结尾。\n  - 0x04 IPv6地址，16个字节长度。\n\n- DST.ADDR 目的地址\n- DST.PORT 网络字节序表示的目的端口\n\n这里也需要注意一下，socks5是支持域名解析的，所以一般我们请求的时候直接使用域名发出请求。\n\n服务端进行请求是，如果是IP则直接进行IP进行请求，如果是域名需要进行解析才能请求。\n\nDST.ADDR这个字段一般是域名字符串的byte数组。\n\n##### 服务端请求命令应答\n\n| VER  | REP  | RSV  | ATYP | BND.ADDR | BND.PORT |\n| ---- | ---- | ---- | ---- | -------- | -------- |\n| 1    | 1    | 0x00 | 1    | 动态     | 2        |\n\n- VER是SOCKS版本，这里应该是0x05；\n- REP应答字段\n  - 0x00表示成功\n  - 0x01普通SOCKS服务器连接失败\n  - 0x02现有规则不允许连接\n  - 0x03网络不可达\n  - 0x04主机不可达\n  - 0x05连接被拒\n  - 0x06 TTL超时\n  - 0x07不支持的命令\n  - 0x08不支持的地址类型\n  - 0x09 - 0xFF未定义\n\n- RSV 0x00，保留\n- ATYP BND.ADDR类型\n  - 0x01 IPv4地址，DST.ADDR部分4字节长度\n  - 0x03域名，DST.ADDR部分第一个字节为域名长度，DST.ADDR剩余的内容为域名，没有\\0结尾。\n  - 0x04 IPv6地址，16个字节长度。\n\n- BND.ADDR 服务器绑定的地址\n- BND.PORT 网络字节序表示的服务器绑定的端口\n\n其实跟请求一样，我们需要关注的REP应答字段，可以打印日志，判断是否连接成功。\n\n------\n\n以上算是握手成功，之后就是数据正常传输，比如客户端访问baidu.com的HTTP数据包，发送到socks服务器，socks服务器访问之后，把响应如实返回给客户端，这就是代理。\n\n##### 最后在来个实例（部分Java代码）\n\n请求握手，协议版本05,客户端只支持用户名和密码认证\n\n```java\n    buffer.clear();\n    buffer.put((byte)0x05);\n    buffer.put((byte)0x01);\n    buffer.put(new byte[]{0x02});\n    buffer.flip();\n    if(write(buffer, true)){\n      SOCKS_PHASE = 1;\n      beginReceive();\n    }\n```\n\n服务端响应：\n\n![image-20200529173135516](https://tva1.sinaimg.cn/large/007S8ZIlly1gf9gatugn8j314g044dgj.jpg)\n\n客户端构造认证请求：\n\n```java\n      byte[] arrayOfByte1 = new byte[4];\n      byte[] arrayOfByte = this.m_Config.Username.getBytes();\n      byte[] arrayOfByte2 = this.m_Config.Password.getBytes();\n      int i = this.m_Config.Username.length();\n      int j = this.m_Config.Password.length();\n\t\t\t//用户名与密码\n      arrayOfByte = StringUtil.getByteArrayByHex(this.m_Config.Username);\n      arrayOfByte2 = StringUtil.getByteArrayByHex(this.m_Config.Password);\n      int k = i+3;\n      arrayOfByte1 = new byte[k+j];\n      arrayOfByte1[0] = 0x01;\n      arrayOfByte1[1] = IntToByte(i)[3];\n      System.arraycopy(arrayOfByte, 0, arrayOfByte1, 2, i);\n      arrayOfByte1[i + 2] = IntToByte(j)[3];\n      System.arraycopy(arrayOfByte2, 0, arrayOfByte1, k, j);\n      paramByteBuffer.clear();\n      paramByteBuffer.put(arrayOfByte1);\n      paramByteBuffer.flip();\n```\n\n服务端响应：\n\n![image-20200529173231196](https://tva1.sinaimg.cn/large/007S8ZIlly1gf9gbr9g4aj316s064wfd.jpg)\n\n\n\n构造请求命令数据包：\n\n```java\n      //校验认证是否成功？\n      if (data.length != 2)\n        return;\n      if (data[0]==0x01 && data[1] ==0x00){\n        System.out.println(\"认证成功，继续\");\n      }else{\n        System.out.println(\"认证失败\");\n        return;\n      }\n      //组装命令过程数据\n      byte[] arrayOfByte1 = this.m_DestAddress.getHostName().getBytes();\n      byte[] portArrayOfByte = unsignedShortToByte2((short)this.m_DestAddress.getPort());\n      byte[] arrayOfByte2 = new byte[arrayOfByte1.length + 5 + portArrayOfByte.length];\n      arrayOfByte2[0] = 5;\n      arrayOfByte2[1] = 1;\n      arrayOfByte2[2] = 0;\n      arrayOfByte2[3] = 3;\n      arrayOfByte2[4] = (byte)arrayOfByte1.length;\n      System.arraycopy(arrayOfByte1, 0, arrayOfByte2, 5, arrayOfByte1.length);\n      System.arraycopy(portArrayOfByte, 0, arrayOfByte2, arrayOfByte1.length + 5, portArrayOfByte.length);\n      paramByteBuffer.clear();\n      paramByteBuffer.put(arrayOfByte2);\n      paramByteBuffer.flip();\n```\n\n服务端响应：\n\n![](https://frankblogimgs.oss-cn-beijing.aliyuncs.com/20200529173805.png)\n\n可以看到服务器应答成功了；之后就是正常的数据传输了。\n\n\n\n\n","tags":["android socks5 proxy"]},{"title":"商业的本质与互联网略读","url":"/2020/05/07/商业的本质与互联网略读/","content":"\n> 本书讲了互联网的历史，一些经济规律与互联网的关系。看似很平常的事情，但是给我耳目一新的感觉，因为之前根本就不知道这些专业名词，对于我这种经济学小白来说，还是有益的。\n\n<!--more-->\n\n#### 思维导图\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1gekz3ohhluj31as0u0491.jpg)\n\n### 专业名词\n\n#### 梅特卡夫效应\n\n网络具有独特的梅特卡夫效应。不限于互联网，电话网，铁路网也具有。\n\n鉴于梅特卡夫效应是理解各类互联网商业模式的关键，我们借助一个简单的概念模型，推导出梅特卡夫效应。与成本结构决定的规模效应和协同效应不同，梅特卡夫效应源自网络用户之间的互动，这个概念模型可以清晰地展示这种互动。让我们设想一家电话公司投资9元，架设a、b两人之间的一条电话线（如图4-1中的粗实线所示），两人每月的通话费为10元，公司的利润为1元。我们在这里略去了除投资之外的所有成本，以便尽可能地保持分析的简洁。如果公司想扩大经营规模和经营收入，决定增加b和c之间的一条线，b和c的通话将给公司带来10元的收入。公司的收入翻番至20元，但成本也翻番到18元，利润2元，都是同幅度线性增长。如果公司想进一步扩大规模，是否要投资再建新线呢？不一定。\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1gejpoq7nzcj30eu0bejsl.jpg)\n\n公司这时发现，可以利用两条线路实现a、b、c三点之间的通信，而不必架设a到c的线路（图4-1中的细线）。公司只需在节点b安装一台电话交换机，当a和b通话时，交换机阻断来自c的呼叫，以避免干扰a和b，当a和c的讲话结束后，交换机再连接c和a。公司以两条线路的成本18元，产生3倍也就是30元的收入，如果忽略交换机的成本，利润为30-18=12元。换句话说，当节点数从2增加到3，也就是增加了50%，收入和利润分别涨了3倍和12倍！感受到网络的魔力了吧？在经济学中，我们称这一现象为“边际收益递增”，意思是每一新增节点的收益不断上升。即使电话交换机是有成本的，也比建一条a到c的线路要小得多，不会因此颠覆边际收益递增的结论。\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1gejppicojaj30fe0cggns.jpg)\n\n让我们继续这个脑力游戏的推理，电话公司再架设一条从c到d的线路，三条线可以使6对客户通话，即ab、ac、ad、bc、bd、cd（见上图），公司的收入增长(60-30)/30=100%，而成本只增加了(27-18)/18=50%，边际收益递增的特征就是收入上涨得比成本更快。推而广之，如果有n-1条线连接第n个客户呢？在这n个人当中，两两通话的可能性有多少？这是一个组合问题，由中学数学知识可知，有n(n-1)/2种可能。如果n=10则有45对节点通话，当n=100时，两人组合的数目达到4950，即电话线路增加10倍，而话费收入增加(4950-45)/45=110倍！电话公司的收入或者网络的价值随用户数呈指数增长，这个关系被称为梅特卡夫定理，用公式表达如下\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1gejpr9j6mcj306802ajrb.jpg)\n\n\n\n公式中，VM代表具有梅特卡夫效应的网络价值，k1是个常数，n是网络节点或网络用户数。读者需要注意，梅特卡夫定律不是物理学意义上的精确定律，而是从大量观察中得出的统计学意义上的近似公式。2015年，中国科学院的三位研究人员分析了脸书和腾讯的实际数据，证明梅特卡夫定律是成立的，互联网公司的市场价值的确与网络节点数的平方成正比。\n\n有意思的是，梅特卡夫从对互联网的观察中得出以他命名的定律，**但并不是所有的互联网公司都具有梅特卡夫效应**。这个强大的效应产生于节点间活跃的互动，对于某一类网络，互动仅发生在不同类别的用户之间，例如淘宝和天猫平台上，互动和交易仅在供应商和消费者之间进行，供应商和供应商之间鲜有交易，消费者和消费者老死不相往来。这类互联网平台的价值源于供应方和需求方的相互吸引和相互促进，遵循学术界的惯例，我们称之为**双边市场效应。**\n\n#### 双边市场效应\n\n我们定义双边市场效应为：**不同类型用户之间正反馈交互所创造的价值**。请注意“不同类型用户”的限定，这意味着**同类用户之间没有互动，双边市场效应因此弱于梅特卡夫效应**。**优步（Uber）等出租车服务平台具有很强的双边市场效应，打车的需求越高，司机的预期收入越高，就有更多的司机加入优步网约车的行列**。另一方面，司机和车辆多，打车就越是方便，并且随着供给的增加，价格会越来越低，于是会吸引更多的消费者。和梅特卡夫效应一样，双边市场效应不是互联网所特有的，甚至不是网络所特有的。实际上，任何一个市场比如浙江义乌小商品市场都可以看到供给和需求的相互促进。采购者愿意去义乌，因为那里有琳琅满目的小商品可供选择。生产厂家愿意在义乌设点，因为那里有来自全国甚至全世界的众多采购者。就供给和需求之间的良性循环而言，义乌和优步没有本质的区别，只不过前者的规模受到物理空间的限制，而后者在互联网虚拟空间中有着似乎是无限的潜力。\n\n区分双边市场效应和梅特卡夫效应是重要的，在双边市场中，并非任意两个节点都可能产生交互。在大多数情况下，同类用户无交互，如图4-3所示，约车平台上的司机b1和b2之间没有沟通，打车人c1和c2彼此素昧平生。4个节点只有4对可能的互动，即b1c1、b1c2、b2c1、b2c2，而图4-2同样4个节点有6对可能的互动。对比图4-2和图4-3，我们可以清晰地从网络结构以及交互的丰富程度上看出梅特卡夫效应和双边市场效应的差别。\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1gejpuudi14j30ry0i00xx.jpg)\n\n\n\n#### 规模效应\n\n规模效益取决于**成本结构**。企业的总成本由**固定成本**和**可变成本**组成，固定成本的比重越大，规模经济效益越好。什么是固定成本？顾名思义，不随产出数量变化的成本，例如厂房、设备、办公楼、电脑信息系统；可变成本则与产量高度相关，像原材料、能源和人工费用，等等。\n\n为了进一步理解规模效应和成本结构的关系，我们构造一个简单的数值案例。假设一家企业的固定成本为1万元，不妨想象为价值1万元的一台冲压机床，一年折旧完毕，摊入成本。工人操作这台设备将2元一件的薄钢板压制成汤匙，为分析的方便，不考虑材料之外的可变成本如人工、能源等。当产量为1000时，总成本等于固定成本加可变成本即材料费，（10000+2×1000）=12000元，单位成本为12000/1000=12元。如果产量增加到3000，单位成本降到（10000+2×3000）/3000=5.3元。当产量为5000时，单位成本更低，只有（10000+2×5000）/5000=4元。单位成本随产量的增加而递减，在汤匙售价不变的情况下，销售每一汤匙的利润（价格减成本）随产量的增加而上升，这就是规模经济效益。从这个例子可以看出，规模经济效益来自分摊到每单位产品上的固定成本的下降。不难验证，固定成本占总成本的比重越高，规模经济效益越好。假如固定成本等于2万元，可变成本仍是每件2元，产量为1000时，平均成本是22元；当产量增加到5000时，平均成本为6元，单位成本降低了12元。在前面的数值案例中，固定成本为1万元时，产量从1000增加到5000，平均成本只降低了12-4=8元。\n\n**需要注意的是，固定成本并非一成不变，经济学教科书经常有这样的表述：固定成本短期不变，长期可变。**这个表述不是很准确，影响固定成本的主要不是时间，而是产量和设计产能。如果一条手机生产线的设计能力是一年10万部，当产量超过10万，比如说达到11万时，厂家就要投资另建一条线，固定成本因此而陡增。互联网公司也是这样，在流量和数据量大到现有数据中心无法承接时，必须投建新机房，购买更多服务器。画成图像的话，横轴是产量，固定成本是一条阶梯形上升的折线。对比之下，餐饮、零售等行业不需要多少固定资产投资，房屋店面都不必自己拥有，租用即可，因而对经营规模的要求比较低，小餐馆、小商店遍地开花，小本生意也可赢利。\n\n规模不可怕，可怕的是同质化，是缺乏创新的能力。很典型的例子，阿里的来往、腾讯的微信、阿里的钉钉\n\n#### 协同效应\n\n与规模效应类似又不尽相同，区别在于前者和单一产品的数量相关，而后者取决于品种的丰富程度。\n\n腾讯建设和维护微信成本是固定的，微信平台上承载的服务越多，电商、广告、游戏、支付、理财、银行等，各项服务的供应商越多，腾讯公司的效益就越好。苹果公司的协同效应体现在数以百万计的App上，新增一个App，比如说爱奇艺，并不消耗苹果的任何资源，却给苹果带来新的收入，即爱奇艺支付的平台使用费。当然，羊毛出在羊身上，最终埋单的还是爱奇艺的用户，消费者成为付费会员后，才能下载它的一些音像产品。免费的音乐和视频虽然也有，但消费者必须先看一两分钟烦人的广告，做广告的商家构成爱奇艺的另一重要收入来源。商家之间的协同也不可忽视，百货大楼里热销的新款跑步鞋有可能带动邻近帽子店的销售。在京东上买了手电，顺便再下单订两节电池。商品种类越是齐全，客户购买的便利性体验越好，百货公司或电商的收入也就越高。\n\n与双边市场效应不同，这个协同效应是品类的丰富。双边市场效应是两边的规模增加而不是品类增加。\n\n### 案例分析\n\n#### 淘宝/天猫\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1gejq2zzk21j30q40n0dn3.jpg)\n\n是一个交易平台，和电商有本质区别；盈利模式是收取交易手续费。\n\n具有双边市场效应，具有规模效应与协同效应，不具有梅特卡夫效应，\n\n#### 京东/亚马逊\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1gejq2hgfryj30v40kmn1b.jpg)\n\n是一个电商，依靠赚取差价获利。\n\n不具有梅特卡夫效应，不具有双边市场效应，具有规模效应与协同效应\n\n#### 共享经济\n\n本质上只是使用了互联网工具的出租公司。\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1gejq4lawnqj30zs0eqtbw.jpg)\n\n#### 图书信息\n\n《信息规则：网络经济的战略方向》\n\n《长尾理论》\n\n《平台革命》\n"},{"title":"Thymeleaf-Layout引起的内存泄露","url":"/2020/04/22/Thymeleaf-Layout-GC-Error/","content":"\n最近线上维护的一个程序经过微服务化之后，出现了很多GC，而且内存被耗尽，小网站，不应该耗尽4G内存,调查了一下原因，原来是\n<!--more-->\n\n服务器硬件信息：\n\nSSD: 80 GB RAID-10\nRAM: 4096 MB\nCPU: 2x Intel Xeon\n\n软件信息：\n\nMySQL,Redis,JDK8,SpringBoot,Thymeleaf\n\nJVM参数：`/opt/jdk1.8.0_191/bin/java -jar -Xloggc:/opt/mb-gc.log -XX:+PrintGC -XX:+PrintGCDateStamps -Xms2500m -Xmx2500m -javaagent:/opt/tingyun/tingyun-agent-java.jar /demo.0.0.1-SNAPSHOT.jar --spring.profiles.active=online`\n\n\n\n用来跑了一些Java程序，运行一天之后，出现OOM异常\n\n```java\norg.springframework.web.util.NestedServletException: Handler dispatch failed; nested exception is java.lang.OutOfMemoryError: GC overhead limit exceeded\n```\n\nGC overhead limit exceeded异常，GOOGLE一番：\n\nThe *java.lang.OutOfMemoryError: GC overhead limit exceeded* error is the JVM’s way of signalling that your application spends too much time doing garbage collection with too little result. By default the JVM is configured to throw this error if it spends more than **98% of the total time doing GC and when after the GC only less than 2% of the heap is recovered**.\n\nJVM抛出 *java.lang.OutOfMemoryError: GC overhead limit exceeded* 错误就是发出了这样的信号: 执行垃圾收集的时间比例太大, 有效的运算量太小. 默认情况下, 如果GC花费的时间超过 **98%**, 并且GC回收的内存少于 **2%**, JVM就会抛出这个错误。\n\n\n\n接着，我们看下JVM内存分配：\n\n使用`JPS`命令找出pid，使用`JMAP -heap ${pid}` 打印内存信息：\n\n问题现场 heap信息：\n\n```shell\nAttaching to process ID 1638, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.191-b12\n\nusing thread-local object allocation.\nParallel GC with 4 thread(s)\n\nHeap Configuration:\n   MinHeapFreeRatio         = 0\n   MaxHeapFreeRatio         = 100\n   MaxHeapSize              = 2621440000 (2500.0MB)\n   NewSize                  = 873463808 (833.0MB)\n   MaxNewSize               = 873463808 (833.0MB)\n   OldSize                  = 1747976192 (1667.0MB)\n   NewRatio                 = 2\n   SurvivorRatio            = 8\n   MetaspaceSize            = 21807104 (20.796875MB)\n   CompressedClassSpaceSize = 1073741824 (1024.0MB)\n   MaxMetaspaceSize         = 17592186044415 MB\n   G1HeapRegionSize         = 0 (0.0MB)\n\nHeap Usage:\nPS Young Generation\nEden Space:\n   capacity = 389021696 (371.0MB)\n   used     = 389021696 (371.0MB)\n   free     = 0 (0.0MB)\n   100.0% used\nFrom Space:\n   capacity = 218103808 (208.0MB)\n   used     = 0 (0.0MB)\n   free     = 218103808 (208.0MB)\n   0.0% used\nTo Space:\n   capacity = 242745344 (231.5MB)\n   used     = 0 (0.0MB)\n   free     = 242745344 (231.5MB)\n   0.0% used\nPS Old Generation\n   capacity = 1747976192 (1667.0MB)\n   used     = 1747822160 (1666.8531036376953MB)\n   free     = 154032 (0.1468963623046875MB)\n   99.99118798066559% used\n```\n\n很显然，Eden区 和Old 区都耗尽了。\n\n我想知道新生代和老年代都存了些什么，使用命令`jmap -dump:live,format=b,file=dump.file ${pid}` \n\n只导出存活对象的堆栈信息\n\n大概有3个G\n\n使用工具分析一下：\n\n```java\nThe class \"nz.net.ultraq.thymeleaf.context.extensions.IContextExtensions\", loaded by \"org.springframework.boot.loader.LaunchedURLClassLoader @ 0x7252ae050\", occupies 2,099,455,296 (96.06%) bytes. The memory is accumulated in one instance of \"java.util.LinkedHashMap\" loaded by \"<system class loader>\".\n\nKeywords\njava.util.LinkedHashMap\nnz.net.ultraq.thymeleaf.context.extensions.IContextExtensions\norg.springframework.boot.loader.LaunchedURLClassLoader @ 0x7252ae050\n```\n\n爆出了内存泄露风险：\n\n继续看，主要看这个`Accumulated Objects in Dominator Tree`看看对象数量：\n\n![](https://tva1.sinaimg.cn/large/007S8ZIlly1ge2fux0uq5j316a0gg7co.jpg)\n\n96%的空间都被 thymeleaf context占用了\n\n怀疑这个有内存泄露，这个类是使用thymeleaf的layout功能，第三方的jar包\n\ngoogle一番，github上面已经有人爆出了类似的BUG：\n\nhttps://github.com/ultraq/thymeleaf-layout-dialect/issues/139\n\nhttps://github.com/ultraq/thymeleaf-layout-dialect/issues/122\n\n然后看帖子说，2.1.0已经解决了\n\n看了下我用的版本是2.0.1 赶紧升级了最新版本；\n\n运行一天结果：\n\n`jmap -heap ${pid}`\n\n```java\nAttaching to process ID 11332, please wait...\nDebugger attached successfully.\nServer compiler detected.\nJVM version is 25.191-b12\n\nusing thread-local object allocation.\nParallel GC with 4 thread(s)\n\nHeap Configuration:\n   MinHeapFreeRatio         = 0\n   MaxHeapFreeRatio         = 100\n   MaxHeapSize              = 2621440000 (2500.0MB)\n   NewSize                  = 873463808 (833.0MB)\n   MaxNewSize               = 873463808 (833.0MB)\n   OldSize                  = 1747976192 (1667.0MB)\n   NewRatio                 = 2\n   SurvivorRatio            = 8\n   MetaspaceSize            = 21807104 (20.796875MB)\n   CompressedClassSpaceSize = 1073741824 (1024.0MB)\n   MaxMetaspaceSize         = 17592186044415 MB\n   G1HeapRegionSize         = 0 (0.0MB)\n\nHeap Usage:\nPS Young Generation\nEden Space:\n   capacity = 829423616 (791.0MB)\n   used     = 23825784 (22.72203826904297MB)\n   free     = 805597832 (768.277961730957MB)\n   2.8725712097399456% used\nFrom Space:\n   capacity = 21495808 (20.5MB)\n   used     = 17248552 (16.449501037597656MB)\n   free     = 4247256 (4.050498962402344MB)\n   80.24146847608613% used\nTo Space:\n   capacity = 22020096 (21.0MB)\n   used     = 0 (0.0MB)\n   free     = 22020096 (21.0MB)\n   0.0% used\nPS Old Generation\n   capacity = 1747976192 (1667.0MB)\n   used     = 102638624 (97.88381958007812MB)\n   free     = 1645337568 (1569.1161804199219MB)\n   5.8718548038439184% used\n```\n\n可以看到，已经正常了；\n\n继续看一下GC频率:`jstat -gc ${pid}`\n\nS0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT\n21504.0 21504.0  0.0   16127.9 809984.0 493815.0 1707008.0   100273.0  112844.0 107384.9 13056.0 12026.0    149    4.369   4      1.156    5.525\n\n\n\nS0C 代表 S0 capacity S0 大小，注意单位是KB 大概21M左右\n\nS1C代表 S1 capacity S1 大小，注意单位是KB 大概21M左右\n\nS0U 代表 S0 used capacity ，S0区使用空间 同理 S1U代表 S1区使用空间\n\n同理其他, C代表初始空间 U代表使用空间，YGC 代表youngCG (count)次数，FGCT 代表 young GC (cost time)\n\n可以看到，Young GC 次数达到了149次，耗时4.369 s\n\n继续看看垃圾回收日志：\n\n```java\n2020-04-21T03:49:51.797+0800: 32225.690: [GC (Allocation Failure)  926931K->105742K(2545152K), 0.0287966 secs]\n2020-04-21T03:57:13.735+0800: 32667.628: [GC (Allocation Failure)  929038K->106728K(2545152K), 0.0513608 secs]\n2020-04-21T04:03:53.071+0800: 33066.965: [GC (Allocation Failure)  930024K->105097K(2545152K), 0.0322447 secs]\n2020-04-21T04:11:00.399+0800: 33494.292: [GC (Allocation Failure)  928393K->105856K(2545152K), 0.0323377 secs]\n2020-04-21T04:20:46.614+0800: 34080.507: [GC (Allocation Failure)  929152K->107559K(2544640K), 0.0285097 secs]\n2020-04-21T04:29:45.171+0800: 34619.064: [GC (Allocation Failure)  930855K->106868K(2545152K), 0.0304927 secs]\n2020-04-21T04:37:42.922+0800: 35096.815: [GC (Allocation Failure)  930164K->106172K(2545664K), 0.0277129 secs]\n2020-04-21T04:42:42.121+0800: 35396.014: [GC (Allocation Failure)  929980K->104085K(2545152K), 0.0260993 secs]\n2020-04-21T04:50:59.664+0800: 35893.557: [GC (Allocation Failure)  927893K->106575K(2545664K), 0.0233603 secs]\n2020-04-21T04:57:57.947+0800: 36311.840: [GC (Allocation Failure)  930383K->106330K(2545152K), 0.0338124 secs]\n2020-04-21T05:04:59.016+0800: 36732.909: [GC (Allocation Failure)  930138K->106005K(2546176K), 0.0251955 secs]\n```\n\n很多的 YGC ，可以看到 old区分配多，但是一直使用很少，我们需要把Eden区适当的调大一些\n\n修改启动参数：\n\n```shell\nnohup /opt/jdk1.8.0_191/bin/java -jar -Xloggc:/opt/mb-gc.log -XX:+PrintGC -XX:+PrintGCDateStamps -XX:NewRatio=1 -XX:SurvivorRatio=6 -Xms2500m -Xmx2500m -javaagent:/opt/tingyun/tingyun-agent-java.jar /demo.jar --spring.profiles.active=online &\n```\n\n`jmap -heap pid`看下是否修改成功：\n\n```java\nHeap Configuration:\n   MinHeapFreeRatio         = 0\n   MaxHeapFreeRatio         = 100\n   MaxHeapSize              = 2621440000 (2500.0MB)\n   NewSize                  = 1310720000 (1250.0MB)\n   MaxNewSize               = 1310720000 (1250.0MB)\n   OldSize                  = 1310720000 (1250.0MB)\n   NewRatio                 = 1\n   SurvivorRatio            = 6\n   MetaspaceSize            = 21807104 (20.796875MB)\n   CompressedClassSpaceSize = 1073741824 (1024.0MB)\n   MaxMetaspaceSize         = 17592186044415 MB\n   G1HeapRegionSize         = 0 (0.0MB)\n\nHeap Usage:\nPS Young Generation\nEden Space:\n   capacity = 1220542464 (1164.0MB)\n   used     = 323484472 (308.4988327026367MB)\n   free     = 897057992 (855.5011672973633MB)\n   26.503336142838204% used\nFrom Space:\n   capacity = 37224448 (35.5MB)\n   used     = 0 (0.0MB)\n   free     = 37224448 (35.5MB)\n   0.0% used\nTo Space:\n   capacity = 48758784 (46.5MB)\n   used     = 0 (0.0MB)\n   free     = 48758784 (46.5MB)\n   0.0% used\nPS Old Generation\n   capacity = 1310720000 (1250.0MB)\n   used     = 85510744 (81.54940032958984MB)\n   free     = 1225209256 (1168.4505996704102MB)\n   6.523952026367187% used\n```\n\n修改成功，看下 `jstat -gc pid`\n\n还是有FGC 和YGC：\n\n```java\nS0C    S1C    S0U    S1U      EC       EU        OC         OU       MC     MU    CCSC   CCSU   YGC     YGCT    FGC    FGCT     GCT\n47616.0 36352.0  0.0    0.0   1191936.0 672473.0 1280000.0   83506.6   98380.0 94049.5 12160.0 11320.6      7    0.322   4      0.939    1.262\n```\n\n继续看下日志：\n\n```java\n2020-04-21T10:56:37.707+0800: 17.685: [Full GC (Metadata GC Threshold)  44082K->42892K(2400256K), 0.1144814 secs]\n2020-04-21T10:56:41.840+0800: 21.817: [GC (Metadata GC Threshold)  884284K->49863K(2400256K), 0.0497769 secs]\n2020-04-21T10:56:41.889+0800: 21.867: [Full GC (Metadata GC Threshold)  49863K->30535K(2400256K), 0.1049150 secs]\n2020-04-21T10:56:47.095+0800: 27.073: [GC (Allocation Failure)  991047K->45635K(2400256K), 0.0237439 secs]\n2020-04-21T10:56:51.833+0800: 31.810: [GC (Metadata GC Threshold)  841845K->56284K(2400256K), 0.0595819 secs]\n2020-04-21T10:56:51.892+0800: 31.870: [Full GC (Metadata GC Threshold)  56284K->53312K(2400256K), 0.2826614 secs]\n2020-04-21T10:57:00.632+0800: 40.609: [GC (Allocation Failure)  1013824K->70909K(2400256K), 0.0262383 secs]\n2020-04-21T10:57:37.503+0800: 77.480: [GC (Allocation Failure)  1031421K->85407K(2513920K), 0.0557805 secs]\n2020-04-21T11:00:13.790+0800: 233.767: [GC (Metadata GC Threshold)  715074K->89727K(2508288K), 0.0624448 secs]\n2020-04-21T11:00:13.853+0800: 233.830: [Full GC (Metadata GC Threshold)  89727K->83506K(2508288K), 0.4372935 secs]\n```\n\n可以看到是由于Metadata GC Threshold触发了FGC；MetaspaceSize 太小了。继续修改，增加参数：\n\n`-XX:MetaspaceSize=128M`\n\n```shell\nnohup /opt/jdk1.8.0_191/bin/java -jar -Xloggc:/opt/mb-gc.log -XX:+PrintGC -XX:+PrintGCDateStamps -XX:NewRatio=1 -XX:SurvivorRatio=6 -XX:MetaspaceSize=128M -Xms2500m -Xmx2500m -javaagent:/opt/tingyun/tingyun-agent-java.jar /demo.jar --spring.profiles.active=online &\n```\n\n好了，GC基本没有，跑段时间在看\n\n"},{"title":"kyro序列化错误","url":"/2019/11/21/kyro-error/","content":"\nKryo序列化时报错：java.lang.ArrayIndexOutOfBoundsException、Buffer overflow\n\n序列化二进制文件不完整\n\n<!--more-->\n\n问题：\n\n1. 序列化对象不完整\n2. 序列化对象比较慢，耗时10-14ms之内\n3. 解决比较慢的问题之后，又出现对象序列化数据不完整问题\n\n\n\njava序列化与kryo序列化得区别？\n\n1. 效率比java序列化高，官方网站有性能测试\n2. kryo不需要实现Serializable接口，而Java需要实现序列化接口\n3. java 序列化支持实例化类的改变，但是kryo不支持；已经经过测试代码证实；\n4. 只导出存活对象的堆栈信息\n\n\n\n正确使用kryo的姿势：\n\n1. 使用对象池来解决非线程安全的问题\n2. 使用Kryo提供的Output对象来获取byte数组，而Output是支持自动扩容的，大于4M的时候；\n\n\n\n池化技术：\n\n数据库连接池，http连接池等；重复利用；\n\n```java\n /**\n     * 初始化kryo池\n     */\n    private static final KryoPool kryoPool = new KryoPool.Builder(new KryoFactory() {\n        public Kryo create() {\n            Kryo kryo = new Kryo();\n            kryo.setInstantiatorStrategy(new Kryo.DefaultInstantiatorStrategy(new StdInstantiatorStrategy()));\n            return kryo;\n        }\n    }).softReferences().build();\n```\n\nKryo池化，主要使用一个软引用队列，如果队列没有则使用工厂创建一个，如果队列有则从队列出队给使用者使用；\n\n使用者使用完之后，进行释放，则kryo对象入队；这样保证kryo的重复利用；\n\n\n\n\n\n自动扩容：\n\n之前的错误原因：\n\n```java\n/** Creates a new Output for writing to an OutputStream. A buffer size of 4096 is used. */\n\tpublic Output (OutputStream outputStream) {\n\t\tthis(4096, 4096);\n\t\tif (outputStream == null) throw new IllegalArgumentException(\"outputStream cannot be null.\");\n\t\tthis.outputStream = outputStream;\n\t}\n\t\n\tpublic Output (int bufferSize, int maxBufferSize) {\n\t\tif (bufferSize > maxBufferSize && maxBufferSize != -1)\n\t\t\tthrow new IllegalArgumentException(\"bufferSize: \" + bufferSize + \" cannot be greater than maxBufferSize: \" + maxBufferSize);\n\t\tif (maxBufferSize < -1) throw new IllegalArgumentException(\"maxBufferSize cannot be < -1: \" + maxBufferSize);\n\t\tthis.capacity = bufferSize;\n\t\tthis.maxCapacity = maxBufferSize == -1 ? Integer.MAX_VALUE : maxBufferSize;\n\t\tbuffer = new byte[bufferSize];\n\t}\n```\n\n看源码以为是最大maxBuffer都是4KB导致的；其实不是，kryo支持自动扩容：\n\n上面这个构造函数，如果指定了外部的一个OutputStream的话，他会每次达到Output的buffer的4096字节后，执行一次刷新操作，把这4096字节刷新到指定的那个输出流，然后清空buffer，继续执行序列化\n\n```java\npublic int writeVarInt (int value, boolean optimizePositive) throws KryoException {\n\t\tif (!optimizePositive) value = (value << 1) ^ (value >> 31);\n\t\tif (value >>> 7 == 0) {\n\t\t\trequire(1);\n\t\t\tbuffer[position++] = (byte)value;\n\t\t\treturn 1;\n\t\t}\n    ...\n}\n\n/** @return true if the buffer has been resized. */\n\tprotected boolean require (int required) throws KryoException {\n        //初始容量够用\n\t\tif (capacity - position >= required) return false;\n\t\t// 申请空间大于最大容量值\n        if (required > maxCapacity)\n\t\t\tthrow new KryoException(\"Buffer overflow. Max capacity: \" + maxCapacity + \", required: \" + required);\n        //刷新缓存\n\t\tflush();\n        //如果没有使用 outputStream，则需要设置最大容量，未超过最大容量则自动扩容\n\t\twhile (capacity - position < required) {\n\t\t\tif (capacity == maxCapacity)\n\t\t\t\tthrow new KryoException(\"Buffer overflow. Available: \" + (capacity - position) + \", required: \" + required);\n\t\t\t// Grow buffer.\n            //自动扩容\n\t\t\tif (capacity == 0) capacity = 1;\n\t\t\tcapacity = Math.min(capacity * 2, maxCapacity);\n\t\t\tif (capacity < 0) capacity = maxCapacity;\n\t\t\tbyte[] newBuffer = new byte[capacity];\n\t\t\tSystem.arraycopy(buffer, 0, newBuffer, 0, position);\n\t\t\tbuffer = newBuffer;\n\t\t}\n\t\treturn true;\n\t}\n\n/** Writes the buffered bytes to the underlying OutputStream, if any. */\n\tpublic void flush () throws KryoException {\n        //如果没有设置outputStream 则直接返回\n\t\tif (outputStream == null) return;\n        //刷缓存到outputStream\n\t\ttry {\n\t\t\toutputStream.write(buffer, 0, position);\n\t\t\toutputStream.flush();\n\t\t} catch (IOException ex) {\n\t\t\tthrow new KryoException(ex);\n\t\t}\n        //重置当前写入位置\n\t\ttotal += position;\n\t\tposition = 0;\n\t}\n```\n\n其实，正确使用kryo的用法有两种：\n\n- 使用最大容量控制对象大小，此时如果序列化大对象超过则扩容，需要设置maxCapacity\n- 使用outputStream来获取真实的对象字节流，这个kryo会自动刷缓存到outputStream中。无需设置maxCapacity\n\n\n\n使用代码：\n\n```java\n            // 不使用outputStream，需要使用size控制\n            Output output = new Output(4096,4096*4);\n            kryo = kryoPool.borrow();\n            kryo.writeObject(output, obj);\n            output.close();\n            bytes[] bytes = output.toBytes();\n```\n\n\n\n```java\n            // 使用outputStream\n            ByteArrayOutputStream outputStream = new ByteArrayOutputStream();\n            Output output = new Output(outputStream);\n            kryo = kryoPool.borrow();\n            kryo.writeObject(output, obj);\n            output.close();\n\t\t\t//此处需要注意，outputStream的结果输出\n            bytes = outputStream.toByteArray();\n\n```\n\n之前的代码把这两种方式进行混用了。\n\n\n\n测试代码：\n\n```java\npublic class TestSerialize implements Serializable {\n\n    public static void main(String[] args) throws Exception {\n        TestSerialize t = new TestSerialize();\n        //t.testKryo();\n        t.testKryoD();\n    }\n\n\n    public void testKryo() throws Exception{\n        User u = new User();\n        u.setName(\"sdfsdf\");\n        u.setUserId(11);\n        byte[] serialize = KryoSerializer.serialize(u);\n        FileOutputStream fileWriter = new FileOutputStream(new File(\"d:/k.bin\"));\n        fileWriter.write(serialize);\n        fileWriter.close();\n    }\n\n    public void testKryoD() throws Exception{\n        FileInputStream in =new FileInputStream(new File(\"d:/k.bin\"));\n        //当文件没有结束时，每次读取一个字节显示\n        byte[] data=new byte[in.available()];\n        in.read(data);\n        in.close();\n        User user = KryoSerializer.deSerialize(data, User.class);\n        System.out.println(user.getName());\n    }\n\n\n\n\n    public void testJava() throws Exception {\n        User u = new User();\n//        u.setUserId(1);\n        u.setName(\"2323\");\n\n        byte[] serialize = JavaSerializer.serialize(u);\n\n        FileOutputStream fileWriter = new FileOutputStream(new File(\"d:/u.bin\"));\n        fileWriter.write(serialize);\n        fileWriter.close();\n\n    }\n\n    public void testJavaD() throws Exception{\n        FileInputStream in =new FileInputStream(new File(\"d:/u.bin\"));\n        //当文件没有结束时，每次读取一个字节显示\n        byte[] data=new byte[in.available()];\n        in.read(data);\n        in.close();\n        User user = JavaSerializer.deSerialize(data, User.class);\n        System.out.println(user.getName());\n    }\n\n\n\n    public class User implements Serializable {\n\n        private static final long serialVersionUID = 229880032075948565L;\n        private Integer userId;\n        private String name;\n        private String sex;\n\n    }\n\n\n}\n```\n\n"},{"title":"JDK8-dynamic-proxy","url":"/2019/04/16/JDK8-dynamic-proxy/","content":"\nJdk动态代理（基于JDK8）原理浅析\n<!--more-->\n\n> Jdk动态代理（基于JDK8）原理浅析\n\nJDK动态代理很容易使用，但是光知道使用不行，还得知道JDK的动态代理是怎么实现的。\n我们例子:\n定义一个接口：\n\n```java\npublic interface Click {\n    void click();\n}\n```\n\n实现类：\n\n```java\npublic class ClickImpl implements Click{\n    @Override\n    public void click() {\n        System.out.println(\"call click action...\");\n    }\n}\n```\n\n动态代理的InvokerHandler:\n\n```java\npublic class ClickInvokerHandler implements InvocationHandler {\n    private Object target;\n    public ClickInvokerHandler(Object target) {\n        this.target = target;\n    }\n    @Override\n    public Object invoke(Object proxy, Method method, Object[] args) throws Throwable {\n        return method.invoke(target,args);\n    }\n}\n```\n\n一般此类可以使用单例模式；\n测试JDK动态代理的方法：\n\n```java\npublic static void main(String[] args) throws Exception {\n        Class<?> proxyClass= Proxy.getProxyClass(JdkProxyTest.class.getClassLoader(),Click.class);\n        final Constructor<?> cons = proxyClass.getConstructor(InvocationHandler.class);\n        final InvocationHandler ih = new ClickInvokerHandler(new ClickImpl());\n        Click click= (Click)cons.newInstance(ih);\n        click.click();\n\n        System.out.println(\"--------------------------------\");\n        Click click1=(Click)Proxy.\n                newProxyInstance(JdkProxyTest.class.getClassLoader(),\n                        new Class<?>[]{Click.class},\n                        new ClickInvokerHandler(new ClickImpl()));\n        click1.click();\n    }\n```\n\n打印数据：\n\n```java\ncall click action...\n--------------------------------\ncall click action...\n```\n\n下面我们带着两个问题看Jdk动态代理原理：\n\n- 怎么生成代理类？\n- InvokerHandler的invoker方法是谁在调用？\n- 生成的代理类如何加载到JVM中?\n\n#####如果生成代理类？\n\n我们可以看看`Proxy.newProxyInstance`方法\n此方法需要三个参数，classLoader,接口定义类数组(click.class),InvocationHandler 实例；\n\n```java\npublic static Object newProxyInstance(ClassLoader loader,\n                                          Class<?>[] interfaces,\n                                          InvocationHandler h)\n        throws IllegalArgumentException\n    {\n    //...略\n     Class<?> cl = getProxyClass0(loader, intfs);\n    //...略\n}    \n```\n\n这个方法就是生成了代理类，我们继续：\n\n```java\nprivate static Class<?> getProxyClass0(ClassLoader loader,\n                                           Class<?>... interfaces) {\n        if (interfaces.length > 65535) {\n            throw new IllegalArgumentException(\"interface limit exceeded\");\n        }\n        //首先从缓存中获取，如果没有创建过，则使用ProxyClassFactory进行创建\n        return proxyClassCache.get(loader, interfaces);\n    }\n```\n\n从proxyClassCache中获取，我们看看proxyClassCache怎么定义的：\n\n```java\nprivate static final WeakCache<ClassLoader, Class<?>[], Class<?>>\n        proxyClassCache = new WeakCache<>(new KeyFactory(), new ProxyClassFactory());\n```\n\n感兴趣的可以看看这个`WeakCache`get()方法，使用了内部类`ProxyClassFactory.apply()`来创建代理类，并缓存。\n1.apply方法里面定义了代理类的类名；\n2.生成代理类的字节码，并加载代理类；\n生成代理类文件：\n\n```java\n byte[] proxyClassFile = ProxyGenerator.generateProxyClass(\n                proxyName, interfaces, accessFlags);\n```\n\n`generateProxyClass`方法中调用`generateClassFile`方法生成class文件；\n可以使用`sun.misc.ProxyGenerator.saveGeneratedFiles`参数来配置，是否保存生成的代理类的class文件；\n感兴趣的可以看下`generateClassFile`这个方法；这个方法默认实现了，Object的hashCode,equals,toString方法；\n\n加载类使用我们classloader来加载：\n这个方法是个`native`方法\n\n```java\ndefineClass0(loader, proxyName,\n                                    proxyClassFile, 0, proxyClassFile.length)\n```\n\nOK,到这里我们看到了怎么生成代理类；这个代理类怎么加载到JVM；\n但是我们还没有看到：invokerHandler的invoker方法何时被调用？\n我们设置配置：`sun.misc.ProxyGenerator.saveGeneratedFiles`为true；\n然后可以看到已经生成了代理类：\n\n```java\npublic final class $Proxy0 extends Proxy implements Click {\n    private static Method m1;\n    private static Method m3;\n    private static Method m2;\n    private static Method m0;\n\n    public $Proxy0(InvocationHandler var1) throws  {\n        super(var1);\n    }\n\n    public final boolean equals(Object var1) throws  {\n        ////...略\n    }\n\n    public final void click() throws  {\n        //...略\n    }\n\n    public final String toString() throws  {\n        ////...略\n    }\n\n    public final int hashCode() throws  {\n       //...略\n    }\n\n    static {\n        try {\n            m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\"));\n            m3 = Class.forName(\"com.tsoft.learning.proxy.dynamic.Click\").getMethod(\"click\");\n            m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\");\n            m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\");\n        } catch (NoSuchMethodException var2) {\n            throw new NoSuchMethodError(var2.getMessage());\n        } catch (ClassNotFoundException var3) {\n            throw new NoClassDefFoundError(var3.getMessage());\n        }\n    }\n}\n```\n\n代理类继承至`Proxy`类，实现了`Click`接口。\n注意static静态块中的代码：\n\n```java\nm3 = Class.forName(\"com.tsoft.learning.proxy.dynamic.Click\").getMethod(\"click\");\n```\n\n从接口中获取方法，如果需要代理接口中没有的方法，就不能使用JDK动态代理。此时，我们需要依靠cglib来做动态代理了。这就是为什么JDK的动态代理需要实现接口的原因。\n我们在看看 `$Proxy0`中的`click`方法：\n\n```java\npublic final void click() throws  {\n        try {\n            super.h.invoke(this, m3, (Object[])null);\n        } catch (RuntimeException | Error var2) {\n            throw var2;\n        } catch (Throwable var3) {\n            throw new UndeclaredThrowableException(var3);\n        }\n    }\n```\n\n里面实际上调用super.h.invoke这个方法，  而这个h对象就是我们的之前的入参：`ClickInvokerHandler `对象；这个对象是使用构成方法注入进去的：\n\n```java\npublic $Proxy0(InvocationHandler var1) throws  {\n        super(var1);\n    }\n```\n\nok，到此，我们提出的三个问题已经回答完毕。    "}]